<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Densely Connected Convolutional Networks - Paper Notes</title>
        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../extra.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->
	
	<script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../..">Paper Notes</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="../..">Home</a>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">CV <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
  <li class="dropdown-submenu">
    <a href="#">ReID</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../201701/video-based-person-re-identification-withaccumulative-motion-context/">Video-based Person Re-identification with Accumulative Motion Context</a>
</li>
            
<li >
    <a href="../../201610/deep-attributes-driven-person-re-identification/">Deep Attributes Driven Person Re-identification</a>
</li>
            
<li >
    <a href="../../201610/human-in-the-loop-person-re-identification/">Human-In-The-Loop Person Re-Identification</a>
</li>
            
<li >
    <a href="../../201610/embedding-deep-metric-for-person-re-identification-a-study-against-large-variation/">Embedding Deep Metric for Person Re-identification A Study Against Large Variation</a>
</li>
            
<li >
    <a href="../../201610/gated-siamese-convolutional-neural-network-architecture-for-human-re-identification/">Gated Siamese Convolutional Neural Network Architecture for Human Re-Identification</a>
</li>
            
<li >
    <a href="../../201610/joint-learning-of-single-image-and-cross-image-representations-for-person-re-identification/">Joint Learning of Single-image and Cross-image Representations for Person Re-identification</a>
</li>
            
<li >
    <a href="../../201609/end-to-end-comparative-attention-networks-for-person-re-identification/">End-to-End Comparative Attention Networks for Person Re-identification</a>
</li>
            
<li >
    <a href="../../201609/recurrent-convolutional-network-for-video-based-person-re-identification/">Recurrent Convolutional Network for Video-based Person Re-Identification</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">Parsing/Segmentation</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../refinenet-multi-path-refinement-networks-for-high-resolution-semantic-segmentation/">RefineNet Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</a>
</li>
            
<li >
    <a href="../pyramid-scene-parsing-network/">Pyramid Scene Parsing Network</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">Detection</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../feature-pyramid-networks-for-object-detection/">Feature Pyramid Networks for Object Detection</a>
</li>
            
<li >
    <a href="../pvanet-deep-but-lightweight-neural-networks-for-real-time-object-detection/">PVANET Deep but Lightweight Neural Networks for Real-time Object Detection</a>
</li>
            
<li >
    <a href="../../201609/faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks/">Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">Captioning</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../201609/hierarchical-recurrent-neural-encoder-for-video-representation-with-application-to-captioning/">Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning</a>
</li>
            
<li >
    <a href="../../201609/describing-videos-by-exploiting-temporal-structure/">Describing Videos by Exploiting Temporal Structure</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">GAN</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../201702/nips-2016-tutorial-gan/">NIPS 2016 Tutorial Generative Adversarial Networks</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">CNN</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../aggregated-residual-transformations-for-deep-neural-networks/">Aggregated Residual Transformations for Deep Neural Networks (ResNeXt)</a>
</li>
            
<li >
    <a href="../xception-deep-learning-with-depthwise-separable-convolutions/">Xception Deep Learning with Depthwise Separable Convolutions</a>
</li>
            
<li class="active">
    <a href="./">Densely Connected Convolutional Networks</a>
</li>
            
<li >
    <a href="../../201608/visualizing-and-understanding-convolutional-networks/">Visualizing and Understanding Convolutional Networks</a>
</li>
            
<li >
    <a href="../../201608/going-deeper-with-convolutions/">Going deeper with convolutions (GoogleNet)</a>
</li>
            
<li >
    <a href="../../201608/network-in-network/">Network in Network</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">Vehicle</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../201702/deep-relative-distance-learning-tell-the-difference-between-similar-vehicles/">Deep Relative Distance Learning Tell the Difference Between Similar Vehicles</a>
</li>
            
<li >
    <a href="../../201702/vehicle-re-identification-for-automatic-video-traffic-surveillance/">Vehicle Re-Identification for Automatic Video Traffic Surveillance</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">NLP <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../201701/lstm-a-search-space-odyssey/">LSTM A Search Space Odyssey</a>
</li>
                            
<li >
    <a href="../language-modeling-with-gated-convolutional-networks/">Language Modeling with Gated Convolutional Networks</a>
</li>
                            
<li >
    <a href="../../201609/memory-networks/">Memory Networks</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Bench <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../201701/mars-a-video-benchmark-for-large-scale-person-re-identification/">MARS A Video Benchmark for Large-Scale Person Re-identification</a>
</li>
                            
<li >
    <a href="../human-attribute-recognition-by-deep-hierarchical-contexts/">Human Attribute Recognition by Deep Hierarchical Contexts (WIDER)</a>
</li>
                            
<li >
    <a href="../../201609/market-1501/">Market-1501</a>
</li>
                            
<li >
    <a href="../../201609/microsoft-video-description-corpus-msvd/">Microsoft Video Description Corpus (MSVD) (Youtube2Text)</a>
</li>
                            
<li >
    <a href="../../201609/tumblr-gif-tgif/">Tumblr GIF (TGIF)</a>
</li>
                            
<li >
    <a href="../../201609/microsoft-research-video-to-text-msr-vtt/">Microsoft Research - Video to Text (MSR-VTT)</a>
</li>
                            
<li >
    <a href="../../201702/vehicle-re-identification-for-automatic-video-traffic-surveillance/">VehReID</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">Action Recognition</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../201701/action-recognition-overview/">Overview</a>
</li>
            
<li >
    <a href="../../201701/UCF101/">UCF101</a>
</li>
            
<li >
    <a href="../../201701/olympic-sports/">Olympic Sports</a>
</li>
            
<li >
    <a href="../../201701/HMDB/">HMDB51</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Other <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../learning-from-simulated-and-unsupervised-images-through-adversarial-training/">Learning from Simulated and Unsupervised Images through Adversarial Training</a>
</li>
                            
<li >
    <a href="../../201701/flownet-learning-optical-flow-with-convolutional-networks/">FlowNet Learning Optical Flow with Convolutional Networks</a>
</li>
                            
<li >
    <a href="../../201609/temporal-segment-networks-towards-good-practices-for-deep-action-recognition/">Temporal Segment Networks Towards Good Practices for Deep Action Recognition</a>
</li>
                            
<li >
    <a href="../../201608/recurrent-models-of-visual-attention/">Recurrent Models of Visual Attention</a>
</li>
                        </ul>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../xception-deep-learning-with-depthwise-separable-convolutions/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../../201608/visualizing-and-understanding-convolutional-networks/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/chaonan99/chaonan99_note/tree/master/paper">
                                <i class="fa fa-github"></i>GitHub
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#densely-connected-convolutional-networks">Densely Connected Convolutional Networks</a></li>
            <li><a href="#intuition">Intuition</a></li>
            <li><a href="#model">Model</a></li>
            <li><a href="#experiment">Experiment</a></li>
            <li><a href="#comment">Comment</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h2 id="densely-connected-convolutional-networks">Densely Connected Convolutional Networks</h2>
<ul>
<li><a href="https://github.com/liuzhuang13/DenseNet">Code</a></li>
<li><a href="http://cn.arxiv.org/pdf/1608.06993v3">paper</a></li>
<li>A dense block with 5 layers and growth rate 4:
<img alt="illustration" src="https://cloud.githubusercontent.com/assets/8370623/17981494/f838717a-6ad1-11e6-9391-f0906c80bc1d.jpg" /></li>
</ul>
<h3 id="intuition">Intuition</h3>
<ul>
<li>Current trend of CNN architecture: create short paths from early layers to later layers.<ul>
<li>ResNet</li>
<li>Highway network: The first network with more than 100 layers, bypassing paths</li>
<li>Stochastic depth: Improves the training of deep residual networks by dropping layers randomly during training, which manages to train a 1202-layer ResNet</li>
<li>FractalNets</li>
</ul>
</li>
<li>Wide filter is helpful.</li>
<li>Connect all layers with each other.</li>
<li>Combine features by concatenating them (ResNet combines by summation).</li>
<li>DenseNet layers are very narrow (12 feature-maps per layer), resulting in less parameters</li>
</ul>
<h3 id="model">Model</h3>
<p><img alt="dense block" src="https://cloud.githubusercontent.com/assets/8370623/17981496/fa648b32-6ad1-11e6-9625-02fdd72fdcd3.jpg" /></p>
<ul>
<li>Dense connectivity: concatenate all the preceding layers:
    <img alt="equation" src="http://latex.codecogs.com/svg.latex?x_l%20%3D%20H_l%28%5Bx_0%2C%20x_1%2C%20%5Cdots%2C%20x_%7Bl-1%7D%5D%29" /></li>
<li>Composite function:
    <code>H_l</code> is defined as <code>BN + ReLU + 3x3 Conv</code></li>
<li>Pooling and dense block<ul>
<li>See figure above</li>
<li><strong>Transition layer</strong> between dense blocks, consist of <code>BN + 1x1 Conv + 2x2 AveragePooing</code></li>
</ul>
</li>
<li>Growth rate <code>k</code>:<ul>
<li>The number of output feature-maps.</li>
<li>The <code>l</code>-th layer will have <code>k x (l-1) + k_0</code> input feature-maps (<code>k_0</code>:input image channels)</li>
</ul>
</li>
<li>Bottleneck layers<ul>
<li>Introduce 1x1 Conv before 3x3 Conv to reduce number of feature-maps will improve computation efficiency.</li>
<li><code>H_l</code> is changed to <code>BN + ReLU + 1x1 Conv + BN + ReLU + 3x3 Conv</code></li>
<li><code>1x1 Conv</code> reduce the input to <code>4k</code> feature-maps in the experiment.</li>
</ul>
</li>
<li>Compression<ul>
<li>Reduce feature-maps number in transition layer by factor <img alt="equation" src="http://latex.codecogs.com/svg.latex?%5Ctheta" /></li>
</ul>
</li>
</ul>
<h3 id="experiment">Experiment</h3>
<ul>
<li>Datasets<ul>
<li>CIFAR-10/100, 32x32<ul>
<li>Zero-padded with 4 pixels on each side</li>
<li>Randomly cropped to again produce 32Ã—32 images</li>
<li>Half of the images are then horizontally mirrored</li>
</ul>
</li>
<li>SVHN (Street View House Numbers), 32x32</li>
<li>ImageNet, 224x224, 1.2m for training, 50000 for validation, 1000 classes</li>
</ul>
</li>
<li>Settings: weight decay 10e-4, Nesterov momentum of 0.9 w\o dampening, learning rate 0.1 with decay scheme, dropout when no data augmentation</li>
<li>Accuracy result:<ul>
<li>3.46% on CIFAR-10, L=190, k=40</li>
<li>17.18% on CIFAR-100, L=190, k=40</li>
<li>1.59% on SVHN, L=100, k=24</li>
</ul>
</li>
<li>Capacity: the performance continues improving when L, k increase, showing the DenseNet is less prone to overfitting (???)</li>
<li>Parameter efficiency.</li>
</ul>
<h3 id="comment">Comment</h3>
<ul>
<li>By <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&amp;hl=en">Xiangyu Zhang</a>.</li>
<li>The reason that DenseNet would work is very likely to be the Pyramidal design (i.e. increasing number of filters along the network flow). Dense connection may not be superior according to his previous experiment. Other papers has demonstrate the effect of Pyramidal design, like Deep Pyramidal Residual Networks, which brings about an obvious 1~2% decrease in error rate on CIFAR.</li>
</ul></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '../..';</script>
        <script data-main="../../mkdocs/js/search.js" src="../../mkdocs/js/require.js"></script>
        <script src="../../js/base.js"></script>
        <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
