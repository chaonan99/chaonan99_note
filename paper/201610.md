## Human Re-identification in Crowd Videos using Personal, Social and Environmental (PSE) Constraints

## Embedding Deep Metric for Person Re-identification: A Study Against Large Variation
* ECCV 2016
* Author: [Hailin Shi](http://www.cbsr.ia.ac.cn/users/hailinshi/), Yang Yang, Xiangyu Zhu, Shengcai Liao, Zhen Lei, Weishi Zheng, [Stan Z. Li](http://www.cbsr.ia.ac.cn/users/szli/)

### Overview
* Re-id research topics:
	* Improving discriminative features.
	* Good metric for comparison.
	* This paper mainly focus on learning good metrics.
* Influenced by face recognition method (the author also works on face recognition).
* Contributions:
	* **Moderate Positive Mining**, a novel positive sample selection strategy for training CNN while the data has large intra-class variations.
	* **Metric weight constraint** (combine Euclidean distance with Mahalanobis distance).

### Moderate positive mining
* Intuitions
	* Positive samples with large distance is harmful.
	* Positive samples with too little distance have little contribution to convergance.
	* What to do: reduce the intra-class variance while preserving the intrinsic graphical structure of pedestrian data via mining the moderate positive pairs in the local range (picture).
	![<picture here>](http://img.blog.csdn.net/20161025124254314)
* Algorithm of choosing moderate positive sample (picture)
	* Compute the distances of 1-all positive&negative samples
	* Mine the hardest negative sample (min distance negative), ![equation](http://latex.codecogs.com/svg.latex?distance%20%3D%20d%5E%2A)
	* Subset of positive samples where distance is larger than ![equation](http://latex.codecogs.com/svg.latex?d%5E%2A)
	* In this subset, find positive pair with min distance -- moderate positive
	![<picture here>](http://img.blog.csdn.net/20161025124317408)

### Metric weight constraint
* Euclidean distance shortcomings:
	* Sensitive to the scale?
	* Blind to the correlation across dimensions
	* Using the Mahalanobis distance is a better choice for multivariate metric, argued by other work
* Another FC after distance between features is calculated to gain Mahalanobis distance.
	* Get Mahalanobis distance
		* ![equation](http://latex.codecogs.com/svg.latex?d%28x_1%2C%20x_2%29%3D%5Csqrt%7B%28x_1-x_2%29%5E%5Cmathbf%7BT%7DM%28x_1-x_2%29%7D)
		* ![equation](http://latex.codecogs.com/svg.latex?M%3DWW%5E%5Cmathbf%7BT%7D) (ensure ![equation](http://latex.codecogs.com/svg.latex?M) is semi-definate matrix)
		* ![equation](http://latex.codecogs.com/svg.latex?d%28x_1%2C%20x_2%29%3D%7C%7CW%5E%5Cmathbf%7BT%7D%28x_1-x_2%29%7C%7C_2)
	* This can be implemented by an FC layer
		![equation](http://latex.codecogs.com/svg.latex?y%3Df%28W%5E%5Cmathbf%7BT%7Dx%29)
* Weight constraint
	* Euclidean better generalization ability, less discriminability.
	* Balance between Euclidean and Mahalanobis distance.
	* ![equation](http://latex.codecogs.com/svg.latex?M) should have large values at the diagonal (Euclidean) and small values elsewhere, by giving constraint:
		* ![equation](http://latex.codecogs.com/svg.latex?%7C%7CWW%5E%5Cmathbf%7BT%7D-I%7C%7C%5E2_F%5Cleq%20C)
	* Further combine the constraint into the loss function as a regularization term:
		* Triplet loss: ![equation](http://latex.codecogs.com/svg.latex?L%20%3D%20d%28x_1%2C%20x_2%5Ep%29%2B%5Bm-d%28x_1%2C%20x_2%5En%29%5D) (margin set to 2 in the experiment)
		* Regularization: ![equation](http://latex.codecogs.com/svg.latex?%5Chat%7BL%7D%3DL%2B%5Cfrac%5Clambda2%7C%7CWW%5E%5Cmathbf%7BT%7D-I%7C%7C%5E2_F) (tune ![equation](http://latex.codecogs.com/svg.latex?%5Clambda) to get the best trade-off)
		* Gradient w.r.t ![equation](http://latex.codecogs.com/svg.latex?W) is computed by ![equation](http://latex.codecogs.com/svg.latex?%5Cfrac%7B%5Cpartial%20%5Chat%7BL%7D%7D%7B%5Cpartial%20W%7D%3D%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20W%7D%2B%5Clambda%28WW%5E%5Cmathbf%7BT%7D-I%29W)

### CNN architecture
![<picture here>](http://img.blog.csdn.net/20161025124349065)

![CNN structure](http://img.blog.csdn.net/20161025124443754)

* 3 branches CNN
	* Original image 128x64 => 3x64x64 (with overlap)
	* Untied (unshared) filter between CNN branches to learn specific features from the different human body parts of pedestrian image.

### Experiments
* Their baseline is very weak (worse than CUHK-03 baseline)
* Three parts are analyzed
	* Moderate positive and hard negative (improve 10%+)
	* Weight constraint, tune on ![equation](http://latex.codecogs.com/svg.latex?%5Clambda) (![equation](http://latex.codecogs.com/svg.latex?%5Clambda) around ![equation](http://latex.codecogs.com/svg.latex?10%5E%7B-2%7D) gets good trade-off)
	* Tied or untied filters between branches (Untied a little better)
* Augmentation
	* Random translation
	* Randomly cropped (0-5 pixels) in horizon and vertical, and stretched to recover the size
* Datasets
	* CUHK03 (Rank-1: 61.32% with hand-crafted bbox, 52.09% with detected bbox)
	* CUHK01 + Market-1501 in training (Rank-1: 86.59%)
	* VIPeR (Rank-1: 43.39%)


## Gated Siamese Convolutional Neural Network Architecture for Human Re-Identification

![2016_10_14_cebff7ce866e92a1c89e96dfc777d19](http://oa5omjl18.bkt.clouddn.com/2016_10_14_cebff7ce866e92a1c89e96dfc777d19.png "Add Description")

* Current state-of-the-art on [Market-1501](201609.md#market-1501).

### Contribution
1. Architecture of baseline siamese network for person re-id.
2. Matching gate between convolutional blocks.

### Matching gate (MG) structure
* Feature summarization
	* Aggregates the local feature along a horizontal stripe.
	* Deal with problem of changed view point (view point change in re-id typically in the horizontal direction, same parts are very likely to be along the same horizontal region).
	* Equation and dimention:
		![equation](http://latex.codecogs.com/svg.latex?y_%7Br1%7D%3Df%28w%2Ax_%7Br1%7D%29); ![equation](http://latex.codecogs.com/svg.latex?y_%7Br2%7D%3Df%28w%2Ax_%7Br2%7D%29)
		where ![equation](http://latex.codecogs.com/svg.latex?x_%7Bri%7D%5Cin%20%5Cmathbb%7BR%7D%5E%7B1%5Ctimes%20c%5Ctimes%20h%7D) is the ![equation](http://latex.codecogs.com/svg.latex?r%5E%7Bth%7D) row of feature map. ![equation](http://latex.codecogs.com/svg.latex?w%5Cin%20%5Cmathbb%7BR%7D%5E%7B1%5Ctimes%20c%5Ctimes%20h%5Ctimes%20h%7D) (maybe ![equation](http://latex.codecogs.com/svg.latex?%5Cmathbb%7BR%7D%5E%7B1%5Ctimes%20c%5Ctimes%201%5Ctimes%20h%7D)) and ![equation](http://latex.codecogs.com/svg.latex?y_%7Br1%7D%5Cin%20%5Cmathbb%7BR%7D%5E%7B1%5Ctimes%201%5Ctimes%20h%7D) (maybe ![equation](http://latex.codecogs.com/svg.latex?%5Cmathbb%7BR%7D%5E%7B1%5Ctimes%201%5Ctimes%20h%5Ctimes%20h%7D)).
* Feature similarity
	* Euclidean distance of ![equation](http://latex.codecogs.com/svg.latex?y_%7Br1%7D) and ![equation](http://latex.codecogs.com/svg.latex?y_%7Br2%7D)
		![equation](http://latex.codecogs.com/svg.latex?g_r%5Ei%3D%5Cexp%28%5Cfrac%7B-%28y_%7Br1%7D%5Ei-y_%7Br2%7D%5Ei%29%5E2%7D%7Bp_i%5E2%7D%29)
		where ![equation](http://latex.codecogs.com/svg.latex?g_r%20%5Cin%20%5Cmathbb%7BR%7D%5E%7B1%5Ctimes%201%5Ctimes%20h%7D)
	* ![equation](http://latex.codecogs.com/svg.latex?p_i) decides the variance of the Gaussian function, learnable, should set a higher initial value.
* Filtering and boosting the features
	* Repeat ![equation](http://latex.codecogs.com/svg.latex?g_r) c times horizontally to obtain ![equation](http://latex.codecogs.com/svg.latex?G_r%5Cin%20%5Cmathbb%7BR%7D%5E%7B1%5Ctimes%20c%5Ctimes%20h%7D).
	* Add filtered feature to original feature.
		![equation](http://latex.codecogs.com/svg.latex?a_%7Br1%7D%5Ei%3Dx_%7Br1%7D%5Ei%2Bx_%7Br1%7D%5Ei%5Codot%20G_r%5Ei)
		![equation](http://latex.codecogs.com/svg.latex?a_%7Br2%7D%5Ei%3Dx_%7Br2%7D%5Ei%2Bx_%7Br2%7D%5Ei%5Codot%20G_r%5Ei)
	* Perform L2 normalization across channels after this

### Result
* Dataset: Market-1501, CUHK-03, VIPeR.
* Baseline S-CNN outperform most CNN approaches. With MG gaining further improvement.
* Visualization of gate. Low gate activation means low similarity.
	![2016_10_14_abc0a52873dfd63db5fbe8ad154b87c](http://oa5omjl18.bkt.clouddn.com/2016_10_14_abc0a52873dfd63db5fbe8ad154b87c.png "Add Description")

## Joint Learning of Single-image and Cross-image Representations for Person Re-identification

<picture here>

### Intuition
* Re-id method: single-image representation (SIR) and cross-image representation (CIR).
* Combine them together!

### Method
* SIR measurements are special cases of CIR-based classification.
	* SIR(Euclidean distance): ![equation](http://latex.codecogs.com/svg.latex?S_%7BSIR%7D%28x_i%2Cx_j%29%3D%7C%7Cf%28x_i%29-f%28x_j%29%7C%7C_2%5E2)
	* CIR: ![equation](http://latex.codecogs.com/svg.latex?S_%7BCIR%7D%28x_i%2Cx_j%29%3Dw%5ETg%28x_i%2Cx_j%29-b)
* Also combine pairwise loss and triplet loss.
	* Pairwise
		![equation](http://latex.codecogs.com/svg.latex?L_%7BSIR%7D%5EP%3D%5Csum_%7Bi%2Cj%7D%5B1%2Bh_%7Bij%7D%28%7C%7Cf%28x_i%29-f%28x_j%29%7C%7C_2%5E2-b_%7BSIR%7D%29%5D_%2B)
		![equation](http://latex.codecogs.com/svg.latex?L_%7BCIR%7D%5EP%3D%5Cfrac%7B%5Calpha_P%7D%7B2%7D%7C%7Cw%7C%7C_2%5E2%2B%5Csum_%7Bi%2Cj%7D%5B1%2Bh_%7Bij%7D%28w%5ETg%28x_i%2Cx_j%29-b_%7BSIR%7D%29%5D_%2B)
		where ![equation](http://latex.codecogs.com/svg.latex?b_%7BSIR%7D%2Cb_%7BCIR%7D) is the distance threshold (margin), ![equation](http://latex.codecogs.com/svg.latex?%5Calpha_P) is the trade-off parameter, which is set to 0.0005 in the experiments
		Combine: ![equation](http://latex.codecogs.com/svg.latex?L%5EP%3DL_%7BSIR%7D%5EP%2B%5Ceta_PL_%7BCIR%7D%5EP)
	* Triplet
		![equation](http://latex.codecogs.com/svg.latex?L_%7BSIR%7D%5ET%3D%5Csum_%7Bi%2Cj%2Ck%7D%5Bb_%7BSIR%7D-%7C%7Cf%28x_i%29-f%28x_k%29%7C%7C_2%5E2%2B%7C%7Cf%28x_i%29-f%28x_j%29%7C%7C_2%5E2%29%5D_%2B)
		![equation](http://latex.codecogs.com/svg.latex?L_%7BCIR%7D%5ET%3D%5Cfrac%7B%5Calpha_P%7D%7B2%7D%7C%7Cw%7C%7C_2%5E2%2B%5Csum_%7Bi%2Cj%2Ck%7D%5Bb_%7BCIR%7D%2Bw%5ETg%28x_i%2Cx_k%29-w%5ETg%28x_i%2Cx_j%29%5D_%2B)
		Combine: ![equation](http://latex.codecogs.com/svg.latex?L%5ET%3DL_%7BSIR%7D%5ET%2B%5Ceta_TL_%7BCIR%7D%5ET)
* Compute cross-image feature map
	![equation](http://latex.codecogs.com/svg.latex?%5Cvarphi_r%28x_i%2Cx_j%29%3Dmax%280%2Cb_r%2B%5Csum_qk_%7Bq%2Cr%7D%2A%5Cphi_q%28x_i%29%2Bl_%7Bq%2Cr%7D%2A%5Cphi_q%28x_j%29%29)

### Result
* Dataset: CUHK-01/03, VIPeR.
* 52.17% on CUHK03.
* Investigation on sensitivity of trade-off parameter.
* 71.8% on CUHK01 (pretrain on CUHK03).
* 35.76% on VIPeR.

## Learning by tracking: Siamese CNN for robust target association

### Problem of tracking
* Most modern approaches use the tracking-by-detection paradigm:
	* Detecting pedestrians in the scene;
	* Link detections over time to create trajectories.
* Linking (data association) problem -- represent as a graph
	* Node: each detection
	* Edge: possible link
	* Data association can be formulated as maximum flow/minimum cost problem, solved with LP
	* Alternative formulations: minimum cliques, MCMC
* Recent trend of data association: complex model, using other technique like reconstruction for multicamera sequences, activity recognition and segmentation.