## Microsoft Research - Video to Text (MSR-VTT)
* [dataset link](http://staff.ustc.edu.cn/~xinmei/Project/Project.html)
* [dataset link 2 (both can download)](http://ms-multimedia-challenge.com/dataset)
* [dataset paper link](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/cvpr16.msr-vtt.tmei_-1.pdf)
* [video to language challenge link](http://ms-multimedia-challenge.com/challenge)

![2016_09_02_f74a3b36446fc20141b4d9ac7a23d4d](http://oa5omjl18.bkt.clouddn.com/2016_09_02_f74a3b36446fc20141b4d9ac7a23d4d.png "Add Description")

### Description
MSR-VTT provides 10K web video clips with 41.2 hours and 200K clip-sentence pairs in total, covering the most comprehensive categories and diverse visual content, and representing the largest dataset in terms of sentence and vocabulary. Each clip is annotated with about 20 natural sentences by 1,327 AMT workers.

### Scale
Total 7180 (train/validate/test: 6513/497/170 ?), in train/validate each has 20 GT sentences. We haven't got the test set sentences yet.

### Duration
Total 41.2 h. The duration of each clip is between 10 and 30 seconds. Yet when I see those in validation set, they are less than 10 s?

### Examples
[see here](http://ms-multimedia-challenge.com/challenge)
