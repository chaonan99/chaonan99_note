## Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks
[paper link](https://arxiv.org/pdf/1506.01497v3.pdf)

## Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning
[paper link](http://arxiv.org/pdf/1511.03476v1.pdf)

![2016_09_01_f5f769c9ad886f8d209bf7d3a425969](http://oa5omjl18.bkt.clouddn.com/2016_09_01_f5f769c9ad886f8d209bf7d3a425969.png "Intuition")

![2016_09_01_90d89552e015c34e67806a4845e0b587](http://oa5omjl18.bkt.clouddn.com/2016_09_01_90d89552e015c34e67806a4845e0b587.png "Whole network")

> Re-read this to get the intuition of current working model.

### Intuitions

1. The author argue that the following solutions to extract temporal information are lack of long term temporal dependency. We need to model video temporal structure with multiple granularities.
	* Two-stream (optical flow is expensive and only short duration feature)
	* 3D Convnet ([Should have a link after reading this])
	* VLAD (know nothing)
2. LSTM can deal with long video, but the **favorable length is 30~80 frames**.
3. Additional non-linearity is helpful, so we can stack LSTMs.

### Model
* Picture one, using stride (= 8) with attention as the input to the first layer lstm (number of steps set to 8).
* Every next layer, use stride to divide previous output into several groups, and use attention on the group to make input.
* Whole model has 2 layers.

### Result
Compare with FGM, Meanpool, SA, S2VT, LSTM-E, p-RNN. The performance is similar with p-RNN on MSVD.

## Describing Videos by Exploiting Temporal Structure
[paper link](https://arxiv.org/pdf/1502.08029v5.pdf)

The first paper using attention on video caption task.

![2016_08_11_76334843cd90cd7af03e2483df49e78](http://oa5omjl18.bkt.clouddn.com/2016_08_11_76334843cd90cd7af03e2483df49e78.png "Structure of video captioning system using temporal attention")

### Model
* [GoogLeNet](201608.md#going-deeper-with-convolutions) to extract frame feature.
* Extract temporal information in a video. Attention->global, 3D-CNN->local. Concatenate 3D-CNN and GoogLeNet feature together.
* 3D-CNN is pre-trained on activity recognition datasets.

### Result
* Do experiments w,w/o attention/3-D CNN, found that the improvements brought by exploiting global and local temporal information are complimentary.

## Microsoft Video Description Corpus (MSVD)
[dataset link](https://www.microsoft.com/en-us/download/details.aspx?id=52422)
[dataset paper link](http://www.cs.utexas.edu/~ml/papers/chen.acl11.pdf)

### Description
This data consists of about 120K sentences collected during the summer of 2010. Workers on Mechanical Turk were paid to watch a short video snippet and then summarize the action in a single sentence. The result is a set of roughly parallel descriptions of more than 2,000 video snippets. Because the workers were urged to complete the task in the language of their choice, both paraphrase and bilingual alternations are captured in the data. We expect this data to be useful for training and testing translation and paraphrase algorithms. A paper describing how the data was created and used is in progress.

### Scale
1970 clips (train/validate/test:1200/100/670), 80k clip-description pairs (**multi-language**), have **audio**.

### Duration
Usually less than 10 seconds.

### Examples

[![2016_09_01_227420e81de92e12b54e9aed867253](http://oa5omjl18.bkt.clouddn.com/2016_09_01_227420e81de92e12b54e9aed867253.png "Add Description")](https://youtu.be/mv89psg6zh4?t=33s)

* Ground truth:
	+ A bird in a sink keeps getting under the running water from a faucet.
	+ A bird is bathing in a sink.
	+ A bird is splashing around under a running faucet.
	+ A bird is bathing in a sink.
	+ A bird is standing in a sink drinking water that is pouring out of the facet.
	+ A faucet is running while a bird stands in the sink below.
	+ ......(many others)

* Some other video:
	+ [A man is riding a motorcycle.](https://youtu.be/msCidKHOh74?t=6m50s)
	+ [The man jumped on the wall.](https://youtu.be/ItFqogTmAvQ?t=48s)
	+ [A man is playing pat-a-cake with a small black dog.](https://youtu.be/eyhzdC936uk?t=15s)

### Papers using the dataset
* [Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning](201609.md#hierarchical-recurrent-neural-encoder-for-video-representation-with-application-to-captioning)
* [Describing Videos by Exploiting Temporal Structure](201609.md#describing-videos-by-exploiting-temporal-structure)

## Youtube2Text
[dataset link](https://www.microsoft.com/en-us/download/details.aspx?id=52422)

This is an alias to [Montreal Video Annotation Dataset (M-VAD)](201609.md#montreal-video-annotation-dataset-m-vad) dataset.

## Montreal Video Annotation Dataset (M-VAD)
[dataset link](https://mila.umontreal.ca/en/publications/public-datasets/m-vad/)

This dataset has a restricted access. Information not collected yet.

## Tumblr GIF (TGIF)
[dataset link](https://github.com/raingo/TGIF-Release)
[dataset paper link](http://arxiv.org/pdf/1604.02748v2.pdf)
[Webpage](http://raingo.github.io/TGIF-Release/)

### Description
The Tumblr GIF (TGIF) dataset contains 100K animated GIFs and 120K sentences describing visual content of the animated GIFs. The animated GIFs have been collected from Tumblr, from randomly selected posts published between May and June of 2015. We provide the URLs of animated GIFs in this release. The sentences are collected via crowdsourcing, with a carefully designed annotation interface that ensures high quality dataset. We provide one sentence per animated GIF for the training and validation splits, and three sentences per GIF for the test split. The dataset shall be used to evaluate animated GIF/video description techniques.

### Scale
102,068 clips (train/validate/test: 80000/10780/11360). 1 caption/clip in train & validate; 3 in test.

### Duration
Overall 103h, 3.65s/clip.

### Examples

![gif](https://38.media.tumblr.com/a73a6a3c2667bb7a0bbbe9854c4f5d86/tumblr_ni2l89yZ7r1u4o6i5o1_500.gif)
a boy and a girl are walking down hand in hand.

![gif](https://33.media.tumblr.com/e24312fa8840e303c64c24a5e09e8381/tumblr_nghtio36IB1rp5w0lo1_400.gif)
a young woman is speaking to another lady and she looks off to the side.

![gif](https://33.media.tumblr.com/00b2f4b7137a0b272eecf86bbe4932c7/tumblr_nrgie93Udc1totisro1_250.gif)
a man strums a guitar with his mouth wide open.

### Papers using the dataset