# 14th August, Sunday

## Works
1. Ask for test annotations of msr-vtt dataset.
2.  Check some of the validation result to see if the caption makes sense.
	* Most of them yield relevent concepts. But they all start with "a man/woman/..."
	* Maybe we can remove "a" in the very beginning of a sentence, and see what the network may learn to be the first word. (Currently most ground truth sentences have "a" in the beginning, so the network may learn that it is safe to predict "a" after start sign)

## TODOs
1. Figure out why the performance on attention model is worse than meanpooling model.
	* Re-read **Describe Temporal Structure** and see if there is some tricks.
2. Report results.
3. Pretraining method.
4. Data augmentation.
5. Visualization of attention