# 16th August, Tuesday

## Works
1. Test module worked on new models.
2. Test over the attention model (gradient check) to ensure the backward function is correct.

## TODOs
1. Attention on both word and image feature.
2. Data augmentation.
3. Visualization of attention.
4. Pre-training on COCO can be tested!
5. Read res-net paper.